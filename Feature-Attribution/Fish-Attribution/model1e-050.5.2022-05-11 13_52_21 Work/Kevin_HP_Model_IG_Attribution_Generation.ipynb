{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kevin HP Model IG Attribution Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0IpaDQ2NW9K"
      },
      "outputs": [],
      "source": [
        "# Attempt to run the full dataset through Integrated Gradients on GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "import string\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "from skimage.filters import sobel\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n"
      ],
      "metadata": {
        "id": "GNnOiaUBNhcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2130884a-b2d2-4557-cd5e-74c22b244f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function takes in a model and replaces inplace relu layers to an independent relu layer\n",
        "def reluToInplaceFalse(model):\n",
        "  for name, child in model.named_children():\n",
        "    if isinstance(child, nn.ReLU):\n",
        "      setattr(child, 'inplace', False)\n",
        "    else:\n",
        "      reluToInplaceFalse(child)\n",
        "\n",
        "#This is the classifier Class.\n",
        "from torchvision.transforms.transforms import RandomRotation, RandomAdjustSharpness, RandomGrayscale\n",
        "\n",
        "class Classifier(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, backbone='resnet', multi_backbone = False, device =\"cuda:0\",dropout_rate = 0.2, do_augmentation = False):\n",
        "    super().__init__()\n",
        "    self.multi_backbone = multi_backbone # Bool: Indicates if we use multibackbone\n",
        "\n",
        "    #In the following secttion we download the appropriatee prettrained model\n",
        "    if backbone == \"vgg19\":\n",
        "      backbone = torchvision.models.vgg19(pretrained=True)\n",
        "      self.out_channels = 25088\n",
        "      \n",
        "    elif backbone == \"resnet18\":\n",
        "      backbone = torchvision.models.resnet18(pretrained=True)\n",
        "      self.out_channels = 512\n",
        "\n",
        "    elif backbone == \"resnet50\":\n",
        "      backbone = torchvision.models.resnet50(pretrained=True)\n",
        "      self.out_channels = 2048\n",
        "\n",
        "    elif backbone == \"Efficientnet b1\":\n",
        "      backbone = torchvision.models.efficientnet_b1(pretrained=True)\n",
        "      self.out_channels = 1280\n",
        "\n",
        "    elif backbone == \"Efficientnet b3\":\n",
        "      backbone = torchvision.models.efficientnet_b3(pretrained=True)\n",
        "      self.out_channels = 1536\n",
        "\n",
        "    elif backbone == \"Efficientnet b5\":\n",
        "      backbone = torchvision.models.efficientnet_b5(pretrained=True)\n",
        "      self.out_channels = 2048\n",
        "\n",
        "    elif backbone == \"Efficientnet b7\":\n",
        "      backbone = torchvision.models.efficientnet_b7(pretrained=True)\n",
        "      self.out_channels = 2560\n",
        "      \n",
        "    # Disabling inplace ReLu becasuse GradCam doesn't work it enabled\n",
        "    reluToInplaceFalse(backbone)\n",
        "     \n",
        "    modules = list(backbone.children())[:-1]\n",
        "    self.do_augmentation = do_augmentation\n",
        "\n",
        "    if self.do_augmentation: #If augmentation is enabled we  init tthe layer\n",
        "      self.augmentation = nn.Sequential(transforms.RandomHorizontalFlip(0.5),\n",
        "                                        transforms.RandomVerticalFlip(0.5),\n",
        "                                        # transforms.RandomPerspective(0.2),\n",
        "                                        transforms.RandomCrop(size=(TARGET_HEIGHT,TARGET_WIDTH)),\n",
        "                                        transforms.RandomRotation(10, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "                                        # RandomAdjustSharpness(,),\n",
        "                                        # RandomGrayscale(),\n",
        "                                        # transforms.RandomAutocontrast()\n",
        "      )\n",
        "\n",
        "    if self.multi_backbone: #We create the backbones and put them on the device\n",
        "      self.backbone1 = nn.Sequential(*copy.deepcopy(modules)).to(device)\n",
        "      self.backbone2 = nn.Sequential(*copy.deepcopy(modules)).to(device)\n",
        "      self.backbone3 = nn.Sequential(*copy.deepcopy(modules)).to(device)\n",
        "      self.backbone4 = nn.Sequential(*copy.deepcopy(modules)).to(device)\n",
        "\n",
        "    else:\n",
        "      self.backbone =  nn.Sequential(*modules).to(device)\n",
        "\n",
        "\n",
        "    #This is the final classification layer\n",
        "    self.fc = nn.Sequential(nn.Dropout(dropout_rate),\n",
        "                            nn.Linear(self.out_channels * 4, 3))                \n",
        "     \n",
        "  def forward(self, x, is_training = True):\n",
        "    # Transform image range from (0, 1) to (-1, 1)\n",
        "    x = x * 2 - 1\n",
        "    if self.do_augmentation and is_training:\n",
        "      imgs = [self.augmentation(x[:,i]) for i in range(4)] #list of 4 images\n",
        "    else:\n",
        "      imgs = [x[:,i] for i in range(4)] #list of 4 images\n",
        "\n",
        "    if self.multi_backbone:\n",
        "      encodings = [self.backbone1(imgs[0]).flatten(1), \n",
        "                   self.backbone2(imgs[1]).flatten(1),\n",
        "                   self.backbone3(imgs[2]).flatten(1),\n",
        "                   self.backbone4(imgs[3]).flatten(1)]\n",
        "    else:\n",
        "      encodings = [self.backbone(img).flatten(1) for img in imgs]\n",
        "\n",
        "    return self.fc(torch.cat(encodings,1))"
      ],
      "metadata": {
        "id": "NP4EZYEuNo1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q-xi6AhNs6P",
        "outputId": "47c5729b-de08-4bec-e888-9915368f8e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the classifier using the following weights\n",
        "# If your directory structure does not resemble the following, you may need to \n",
        "model = torch.load(\"drive/MyDrive/Fish Attribution/\" + 'model1e-050.5.2022-05-11 13_52_21.pt', map_location=\"cpu\")\n",
        "model.eval()\n",
        "model.zero_grad()"
      ],
      "metadata": {
        "id": "OoCGU15ONvLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "# check that cuda is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5u63ctDOsa8",
        "outputId": "3fbd388c-f53f-4e13-dfc2-1fff032f8d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the model onto the GPU for faster evaluation\n",
        "# model.to(device)"
      ],
      "metadata": {
        "id": "Jf2AW3cAPK9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the raw fish images\n",
        "# WARNING: The following WILL use a large amount of RAM\n",
        "import numpy as np\n",
        "\n",
        "X_PATH = \"/content/drive/Shareddrives/Exploding Gradients/Old Data/x_train_b_cropped_v1.npy\"\n",
        "Y_PATH= \"/content/drive/Shareddrives/Exploding Gradients/Old Data/y_train_b_v1.npy\"\n",
        "\n",
        "x = np.load(X_PATH)\n",
        "y = np.load(Y_PATH)\n",
        "\n",
        "# 285 instances, currently the shapes are off, see next cell for fix\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkGxS_FGPMcS",
        "outputId": "6457fe83-409f-4ab0-d411-1905f05c9e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(285, 4, 130, 750, 3)\n",
            "(285, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conver to PyTorch tensors from raw numpy arrays and\n",
        "# fix the dimensions\n",
        "tensor_x = torch.Tensor(x) \n",
        "tensor_y = torch.Tensor(y).long()\n",
        "\n",
        "tensor_x = torch.swapaxes(tensor_x,2,4)\n",
        "tensor_x = torch.swapaxes(tensor_x,3,4)"
      ],
      "metadata": {
        "id": "QfanEgxePUwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 258 pieces of data, with 4 images per instance\n",
        "# and each image being full color (RGB) with 130x750 pixels\n",
        "# (The original fish images are of larger dimension but\n",
        "# an autocropper was created to narrow down the focus)\n",
        "tensor_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qN25qRoSCqw",
        "outputId": "f4f53bec-922b-4229-944e-2ecfdd65c598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([285, 4, 3, 130, 750])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PyTorch dataloader to feed data to the model\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "attribution_ds = TensorDataset(tensor_x ,tensor_y)\n",
        "\n",
        "#attribution_dl = DataLoader(attribution_ds,10,shuffle = True)\n",
        "\n",
        "# Delete the raw numpy arrays from RAM, there's no need for them\n",
        "# now that they exist as PyTorch tensors\n",
        "del x,y"
      ],
      "metadata": {
        "id": "E0aW5wDHPheg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Captum for Feature Attribution\n",
        "!pip install -q captum\n",
        "\n",
        "from captum.attr import *"
      ],
      "metadata": {
        "id": "LccLQ_KQaL9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee4da62-5dc9-49db-f50e-dc4dbf4a1a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 153 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 163 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 174 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 184 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 194 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 204 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 215 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 225 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 266 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 307 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 317 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 327 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 337 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 348 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 358 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 368 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 378 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 389 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 399 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 409 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 419 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 430 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 440 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 450 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 460 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 471 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 481 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 501 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 512 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 522 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 532 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 542 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 552 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 563 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 573 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 583 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 593 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 604 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 614 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 624 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 634 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 645 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 655 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 665 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 675 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 686 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 696 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 706 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 727 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 737 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 747 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 757 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 768 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 778 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 788 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 798 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 808 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 819 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 829 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 839 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 849 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 860 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 870 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 880 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 890 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 901 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 911 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 921 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 931 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 942 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 952 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 962 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 972 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 983 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 993 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.0 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.0 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.0 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.0 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 15.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.to(device)\n",
        "ig = IntegratedGradients(model)"
      ],
      "metadata": {
        "id": "xTrduLUqSk0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3156VHKQ0iHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRqaA6sT3gpx",
        "outputId": "0a558344-097f-4184-d62c-977f53048d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!printenv | grep \"PYTORCH\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkg8oFxc06Ef",
        "outputId": "07b0a46f-aeb8-4cd8-e469-4f31b8985945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save each batch of attributions\n",
        "all_attributions = []\n",
        "# you do 40 at a time here\n",
        "batch_num = 1\n",
        "for images, labels in attribution_ds:\n",
        "  print(f\"Processing batch #{batch_num}\") # for 285 instances 40 at a time, should process 8 batches\n",
        "  batch_num += 1\n",
        "  # send images to the GPU\n",
        "  #images = images.to(device)\n",
        "  # create new class-representative labels\n",
        "  # get the attributions\n",
        "  ## important arguments:\n",
        "  ## n_steps: number of steps that should be executed for Integration\n",
        "  ## internal_batch_size: \n",
        "  attributions = ig.attribute(images.unsqueeze(0), target=labels, baselines = (images.unsqueeze(0) * 0), n_steps = 50, internal_batch_size = 40)\n",
        "  # Convert the attribution data to CPU and save it in the list\n",
        "  all_attributions.append(attributions.cpu())\n",
        "  del images, labels, attributions\n",
        "  #torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIns3v97SoGX",
        "outputId": "e4ba283b-d6de-4267-d862-e4c9ed56ca25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch #1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "k6L-sguNyWOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3J_xnbUVybz8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}