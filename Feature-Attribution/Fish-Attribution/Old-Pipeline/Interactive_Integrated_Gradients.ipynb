{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interactive Integrated Gradients.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jhF0qRpXbbC"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "import base64\n",
        "from PIL import Image\n",
        "\n",
        "from bokeh import plotting, palettes\n",
        "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "plotting.output_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.colors as mplc\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Y1ynGagnXgk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from captum.attr import *"
      ],
      "metadata": {
        "id": "Es9pa7QEXnhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need original image AND the attribution data to pull this off\n",
        "def embeddableImage(image_cluster, attribution_cluster):\n",
        "    # data should be [4, 3, 200, 1024] instance\n",
        "    encoded_subimages = []\n",
        "    for sub_image, sub_attribution in zip(image_cluster, attribution_cluster):\n",
        "      # need to normalize each image to be between 0.0 to 1.0\n",
        "      # can assume that everything is already a numpy array\n",
        "      #norm = mplc.Normalize(vmin = np.amin(sub_image), vmax = np.amax(sub_image))\n",
        "      #img_data = (norm(sub_image) * 255).astype(np.uint8).transpose(1, 2, 0)\n",
        "      #image = Image.fromarray(img_data, mode='RGB')\n",
        "      print(sub_image.shape)\n",
        "      fig, _ = visualization.visualize_image_attr(sub_attribution.transpose(1,2,0), sub_image.transpose(1,2,0), method=\"blended_heat_map\", sign=\"absolute_value\", outlier_perc=0);\n",
        "      buffer = BytesIO()\n",
        "      #image.save(buffer, format='png')\n",
        "      fig.savefig(buffer, format='png', bbox_inches='tight')\n",
        "      encoded_subimages.append('data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode())\n",
        "    return encoded_subimages"
      ],
      "metadata": {
        "id": "NqxohlyoXiac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# x and attributions MUST have the same dimensions!\n",
        "def umapPlot(embedding, x, y, attributions, yTrue=None, title=''):\n",
        "    \"\"\" Plot the embedding of X and y with popovers using Bokeh \"\"\"\n",
        "    \n",
        "    df = pd.DataFrame(embedding, columns=('x', 'y'))\n",
        "    # for each image should be able to apply the embeddable image function\n",
        "    # list of lists [rows x columns], x instances with 4 columns\n",
        "    sub_images = np.array(list(map(embeddableImage, x, attributions)))\n",
        "    for i in range(4):\n",
        "      df['image'+str(i+1)] = sub_images[:,i]\n",
        "    df['class'] = [str(d) for d in y]\n",
        "    df['index'] = list(range(len(y)))\n",
        "    if yTrue is not None:\n",
        "        df['trueDigit'] = [str(d) for d in yTrue]\n",
        "\n",
        "    datasource = ColumnDataSource(df)\n",
        "\n",
        "    colorMapping = CategoricalColorMapper(factors=np.arange(10).astype(np.str), palette=palettes.Spectral10)\n",
        "\n",
        "    plotFigure = plotting.figure(\n",
        "        title=title,\n",
        "        plot_width=600,\n",
        "        plot_height=600,\n",
        "        tools=('pan, wheel_zoom, reset')\n",
        "    )\n",
        "\n",
        "    if yTrue is None:\n",
        "        tooltip = \"\"\"\n",
        "            <div>\n",
        "                <div>\n",
        "                    <img src='@image1' style='float: left; width:256px; height:50px; margin: 5px 5px 5px 5px'/>\n",
        "                </div>\n",
        "                <div>\n",
        "                    <img src='@image2' style='float: left; width:256px; height:50px; margin: 5px 5px 5px 5px'/>\n",
        "                </div>\n",
        "                <div>\n",
        "                    <img src='@image3' style='float: left; width:256px; height:50px; margin: 5px 5px 5px 5px'/>\n",
        "                </div>\n",
        "                <div>\n",
        "                    <img src='@image4' style='float: left; width:256px; height:50px; margin: 5px 5px 5px 5px'/>\n",
        "                </div>\n",
        "                <div>\n",
        "                    <span style='font-size: 16px; color: #224499'>Class:</span>\n",
        "                    <span style='font-size: 18px'>@class</span>\n",
        "                    <span style='font-size: 16px; color: #224499'>Index:</span>\n",
        "                    <span style='font-size: 18px'>@index</span>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "    else:\n",
        "        tooltip = \"\"\"\n",
        "            <div>\n",
        "                <div>\n",
        "                    <img src='@image' style='float: left; margin: 5px 5px 5px 5px'/>\n",
        "                </div>\n",
        "                <div>\n",
        "                    <span style='font-size: 16px; color: #224499'>Digit:</span>\n",
        "                    <span style='font-size: 18px'>@digit (true: @trueDigit)</span>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "    plotFigure.add_tools(HoverTool(tooltips=tooltip))\n",
        "\n",
        "    plotFigure.circle(\n",
        "        'x', 'y',\n",
        "        source=datasource,\n",
        "        color=dict(field='class', transform=colorMapping),\n",
        "        line_alpha=0.6, fill_alpha=0.6, size=8\n",
        "    )\n",
        "    plotting.show(plotFigure)\n",
        "    \n",
        "    return plotFigure"
      ],
      "metadata": {
        "id": "UJSW0WWiXqQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.load(\"x_subset.tensor\")\n",
        "y = torch.load(\"y_subset.tensor\")"
      ],
      "metadata": {
        "id": "fCeAKMReXtX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_attributions = torch.load(\"integrated_gradients_combined_attributions.tensor\")"
      ],
      "metadata": {
        "id": "c6qKPCwjXu62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "reducerFish = umap.UMAP(n_neighbors = 20,min_dist=0.5, verbose = True)\n",
        "embeddingFish = reducerFish.fit_transform(torch.reshape(combined_attributions, (50, 2457600)))"
      ],
      "metadata": {
        "id": "rLkjanAXXwwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_combined_attributions = combined_attributions + 0.3 # definitely improper but avoids "
      ],
      "metadata": {
        "id": "lbTucqxDXzK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = umapPlot(embeddingFish, x.numpy(), y.squeeze().numpy(), scaled_combined_attributions.numpy(), title='UMAP projection of the Zebrafish dataset with Integrated Gradients Applied')"
      ],
      "metadata": {
        "id": "PvihCYE6X1wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.io import show\n",
        "show(fig)"
      ],
      "metadata": {
        "id": "kQaoIlLyX8Sk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}